# Qwen3-8B Fine-tuning Application

á»¨ng dá»¥ng Python chuyÃªn nghiá»‡p Ä‘á»ƒ fine-tuning model Qwen3-8B vá»›i kháº£ nÄƒng xá»­ lÃ½ Ä‘a dáº¡ng Ä‘á»‹nh dáº¡ng file vÃ  chat interface.

## ğŸš€ TÃ­nh nÄƒng chÃ­nh

- **Fine-tuning Qwen3-8B** vá»›i dá»¯ liá»‡u tá»« nhiá»u Ä‘á»‹nh dáº¡ng file (.csv, .txt, .pdf, .docx, .xlsx)
- **REST API** Ä‘á»ƒ quáº£n lÃ½ quÃ¡ trÃ¬nh fine-tuning
- **Chat interface** vá»›i kháº£ nÄƒng upload file bá»• sung
- **Database** lÆ°u trá»¯ thÃ´ng tin fine-tuning
- **Web interface** thÃ¢n thiá»‡n ngÆ°á»i dÃ¹ng (Streamlit)
- **File Upload System** há»— trá»£ nhiá»u Ä‘á»‹nh dáº¡ng file
- **Model Management** quáº£n lÃ½ vÃ  theo dÃµi cÃ¡c model Ä‘Ã£ fine-tune
- **Automatic Tokenizer Fallback** - Tá»± Ä‘á»™ng sá»­ dá»¥ng local tokenizer náº¿u cáº§n

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

- Python 3.8+
- RAM: 16GB+ (cho fine-tuning)
- GPU: NVIDIA GPU vá»›i CUDA (khuyáº¿n nghá»‹)
- Disk space: 20GB+ cho model vÃ  dá»¯ liá»‡u

## ğŸ› ï¸ CÃ i Ä‘áº·t

```bash
# Clone repository
git clone <repository-url>
cd qwen3-8b-finetuning

# Táº¡o virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c
venv\Scripts\activate  # Windows

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt

# CÃ i Ä‘áº·t accelerate (báº¯t buá»™c cho device_map)
pip install accelerate
```

## âš™ï¸ Cáº¥u hÃ¬nh

1. Táº¡o file `.env`:
```bash
cp .env.example .env
```

2. Cáº­p nháº­t cÃ¡c biáº¿n mÃ´i trÆ°á»ng trong `.env`:
```env
# Database Configuration
DATABASE_URL=sqlite:///./finetuning.db

# Model Configuration
MODEL_NAME=Qwen/Qwen3-8B
BASE_MODEL_PATH=./models/base
FINETUNED_MODEL_PATH=./models/finetuned

# Hugging Face Configuration
HF_TOKEN=your_huggingface_token_here
HF_REPO_ID=your_username/your_model_name

# Security
SECRET_KEY=your_secret_key_here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30

# File Upload Configuration
MAX_FILE_SIZE=104857600
UPLOAD_DIR=./uploads
ALLOWED_EXTENSIONS=["csv", "txt", "pdf", "docx", "xlsx", "jpg", "jpeg", "png"]

# Fine-tuning Configuration
DEFAULT_LEARNING_RATE=2e-5
DEFAULT_BATCH_SIZE=4
DEFAULT_EPOCHS=3
DEFAULT_MAX_LENGTH=512
DEFAULT_WARMUP_STEPS=100

# Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=True
```

## ğŸš€ Sá»­ dá»¥ng

### Khá»Ÿi Ä‘á»™ng API server
```bash
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```
- API Documentation: http://localhost:8000/docs
- API Base URL: http://localhost:8000

### Khá»Ÿi Ä‘á»™ng Streamlit interface
```bash
streamlit run app/streamlit_app.py
```
- Web Interface: http://localhost:8501

### Cháº¡y cáº£ hai cÃ¹ng lÃºc
```bash
python run.py --both
```

## âš¡ï¸ Táº£i model vá» local Ä‘á»ƒ tÄƒng tá»‘c vÃ  trÃ¡nh timeout

**Khuyáº¿n nghá»‹:** TrÆ°á»›c khi cháº¡y backend láº§n Ä‘áº§u, hÃ£y táº£i model vá» local Ä‘á»ƒ trÃ¡nh timeout khi táº£i model lá»›n tá»« Hugging Face.

### BÆ°á»›c 1: Táº£i model vá» local (khuyáº¿n nghá»‹ dÃ¹ng snapshot)

Cháº¡y script sau Ä‘á»ƒ táº£i toÃ n bá»™ snapshot model vá» thÆ° má»¥c local (vÃ­ dá»¥ cho Qwen/Qwen3-8B):

```bash
python download_snapshot.py --repo_id Qwen/Qwen3-8B --output_dir ./models/base/Qwen3-8B
```

> Náº¿u báº¡n chá»‰ muá»‘n táº£i model/tokenizer (khÃ´ng pháº£i toÃ n bá»™ snapshot), cÃ³ thá»ƒ dÃ¹ng script download_model.py:
> ```bash
> python download_model.py --model_repo Qwen/Qwen3-8B --output_dir ./models/base/Qwen3-8B
> ```

### BÆ°á»›c 2: Cáº¥u hÃ¬nh backend Æ°u tiÃªn load model tá»« local

- Máº·c Ä‘á»‹nh, backend sáº½ tá»± Ä‘á»™ng Æ°u tiÃªn load model tá»« `./models/base/Qwen3-8B` náº¿u thÆ° má»¥c nÃ y tá»“n táº¡i vÃ  khÃ´ng rá»—ng.
- Náº¿u muá»‘n chá»‰ Ä‘á»‹nh Ä‘Æ°á»ng dáº«n khÃ¡c, Ä‘áº·t biáº¿n mÃ´i trÆ°á»ng:
  ```bash
  export BASE_MODEL_LOCAL_DIR=/duong/dan/den/thu_muc_model
  ```
- Sau Ä‘Ã³ khá»Ÿi Ä‘á»™ng láº¡i backend.

## ğŸ”§ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p vÃ  cÃ¡ch kháº¯c phá»¥c

#### 1. Lá»—i "accelerate required"
```
Error: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`.
```
**Giáº£i phÃ¡p:**
```bash
pip install accelerate
```

#### 2. Lá»—i "Qwen2Tokenizer does not exist"
```
Error: Tokenizer class Qwen2Tokenizer does not exist or is not currently imported.
```
**Giáº£i phÃ¡p:**
- Cáº­p nháº­t transformers lÃªn phiÃªn báº£n má»›i nháº¥t:
  ```bash
  pip install --upgrade transformers
  ```
- á»¨ng dá»¥ng Ä‘Ã£ cÃ³ fallback mechanism Ä‘á»ƒ tá»± Ä‘á»™ng sá»­ dá»¥ng local tokenizer náº¿u cáº§n.

#### 3. Lá»—i bitsandbytes GPU support
```
Warning: The installed version of bitsandbytes was compiled without GPU support.
```
**Giáº£i phÃ¡p:**
- Náº¿u báº¡n cÃ³ GPU vÃ  muá»‘n dÃ¹ng quantization:
  ```bash
  pip uninstall bitsandbytes
  pip install bitsandbytes
  ```
- Náº¿u khÃ´ng cÃ³ GPU, cÃ³ thá»ƒ bá» qua cáº£nh bÃ¡o nÃ y.

#### 4. Lá»—i timeout khi táº£i model
**Giáº£i phÃ¡p:**
- Táº£i model vá» local trÆ°á»›c (xem pháº§n "Táº£i model vá» local" á»Ÿ trÃªn)
- Hoáº·c tÄƒng timeout trong cáº¥u hÃ¬nh

#### 5. Lá»—i CUDA out of memory
**Giáº£i phÃ¡p:**
- Giáº£m batch_size trong cáº¥u hÃ¬nh fine-tuning
- Sá»­ dá»¥ng quantization (4-bit hoáº·c 8-bit)
- Giáº£m max_length

## ğŸ“¡ API Endpoints

### Fine-tuning
- `POST /api/finetune/upload` - Upload file Ä‘á»ƒ fine-tuning
- `POST /api/finetune/start` - Báº¯t Ä‘áº§u fine-tuning
- `GET /api/finetune/status/{job_id}` - Kiá»ƒm tra tráº¡ng thÃ¡i fine-tuning
- `GET /api/finetune/history` - Lá»‹ch sá»­ fine-tuning

### Chat
- `POST /api/chat` - Chat vá»›i model Ä‘Ã£ fine-tune
- `POST /api/chat/upload` - Upload file bá»• sung cho chat
- `POST /api/chat/session` - Táº¡o session chat má»›i

### Model Management
- `GET /api/models` - Danh sÃ¡ch models
- `GET /api/models/{model_id}` - ThÃ´ng tin chi tiáº¿t model
- `DELETE /api/models/{model_id}` - XÃ³a model

### File Upload
- `POST /api/upload/file` - Upload má»™t file
- `POST /api/upload/files` - Upload nhiá»u files
- `GET /api/upload/list` - Danh sÃ¡ch files Ä‘Ã£ upload
- `GET /api/upload/config` - Cáº¥u hÃ¬nh upload

## ğŸ”Œ API Usage Examples

### Sá»­ dá»¥ng vá»›i Curl

#### 1. Health Check
```bash
curl -X GET "http://localhost:8000/api/upload/config"
```

#### 2. Upload File
```bash
curl -X POST "http://localhost:8000/api/upload/file" \
  -H "Content-Type: multipart/form-data" \
  -F "file=@/path/to/your/file.csv"
```

#### 3. Start Fine-tuning
```bash
curl -X POST "http://localhost:8000/api/finetune/start" \
  -H "Content-Type: application/json" \
  -d '{
    "model_name": "my-finetuned-model",
    "base_model": "Qwen/Qwen3-8B",
    "learning_rate": 2e-5,
    "batch_size": 4,
    "epochs": 3,
    "max_length": 512,
    "warmup_steps": 100,
    "data_files": ["path/to/uploaded/file.csv"]
  }'
```

#### 4. Check Fine-tuning Status
```bash
curl -X GET "http://localhost:8000/api/finetune/status/job_12345678"
```

#### 5. Create Chat Session
```bash
curl -X POST "http://localhost:8000/api/chat/session" \
  -H "Content-Type: application/json" \
  -d '{
    "model_id": "model_12345678",
    "session_name": "My Chat Session"
  }'
```

#### 6. Send Chat Message
```bash
curl -X POST "http://localhost:8000/api/chat/send" \
  -H "Content-Type: application/json" \
  -d '{
    "session_id": "session_12345678",
    "message": "Hello, how are you?",
    "model_id": "model_12345678"
  }'
```

#### 7. Get Model List
```bash
curl -X GET "http://localhost:8000/api/models"
```

#### 8. Get Model Details
```bash
curl -X GET "http://localhost:8000/api/models/model_12345678"
```

### Sá»­ dá»¥ng vá»›i Postman

#### 1. Setup Postman Collection

Táº¡o collection má»›i vá»›i base URL: `http://localhost:8000`

#### 2. Health Check Request
- **Method**: GET
- **URL**: `{{base_url}}/api/upload/config`
- **Headers**: None

#### 3. Upload File Request
- **Method**: POST
- **URL**: `{{base_url}}/api/upload/file`
- **Headers**: 
  - `Content-Type: multipart/form-data`
- **Body**: 
  - Type: `form-data`
  - Key: `file`
  - Type: `File`
  - Value: Select your file

#### 4. Start Fine-tuning Request
- **Method**: POST
- **URL**: `{{base_url}}/api/finetune/start`
- **Headers**:
  - `Content-Type: application/json`
- **Body** (raw JSON):
```json
{
  "model_name": "my-finetuned-model",
  "base_model": "Qwen/Qwen3-8B",
  "learning_rate": 2e-5,
  "batch_size": 4,
  "epochs": 3,
  "max_length": 512,
  "warmup_steps": 100,
  "data_files": ["path/to/uploaded/file.csv"]
}
```

#### 5. Check Status Request
- **Method**: GET
- **URL**: `{{base_url}}/api/finetune/status/{{job_id}}`
- **Headers**: None

#### 6. Create Chat Session Request
- **Method**: POST
- **URL**: `{{base_url}}/api/chat/session`
- **Headers**:
  - `Content-Type: application/json`
- **Body** (raw JSON):
```json
{
  "model_id": "model_12345678",
  "session_name": "My Chat Session"
}
```

#### 7. Send Chat Message Request
- **Method**: POST
- **URL**: `{{base_url}}/api/chat/send`
- **Headers**:
  - `Content-Type: application/json`
- **Body** (raw JSON):
```json
{
  "session_id": "session_12345678",
  "message": "Hello, how are you?",
  "model_id": "model_12345678"
}
```

#### 8. Get Models Request
- **Method**: GET
- **URL**: `{{base_url}}/api/models`
- **Headers**: None

### Environment Variables cho Postman

Táº¡o environment vá»›i cÃ¡c variables:
- `base_url`: `http://localhost:8000`
- `job_id`: (sáº½ Ä‘Æ°á»£c set tá»« response)
- `model_id`: (sáº½ Ä‘Æ°á»£c set tá»« response)
- `session_id`: (sáº½ Ä‘Æ°á»£c set tá»« response)

### Test Scripts cho Postman

#### Set Job ID tá»« Fine-tuning Response
```javascript
// Trong Tests tab cá»§a Start Fine-tuning request
if (pm.response.code === 200) {
    const response = pm.response.json();
    pm.environment.set("job_id", response.job_id);
}
```

#### Set Model ID tá»« Model List Response
```javascript
// Trong Tests tab cá»§a Get Models request
if (pm.response.code === 200) {
    const response = pm.response.json();
    if (response.models && response.models.length > 0) {
        pm.environment.set("model_id", response.models[0].model_id);
    }
}
```

#### Set Session ID tá»« Create Session Response
```javascript
// Trong Tests tab cá»§a Create Chat Session request
if (pm.response.code === 200) {
    const response = pm.response.json();
    pm.environment.set("session_id", response.session_id);
}
```

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ config.py              # Configuration
â”‚   â”œâ”€â”€ database.py            # Database setup
â”‚   â”œâ”€â”€ models/                # Database models
â”‚   â”‚   â”œâ”€â”€ finetune_job.py    # Fine-tuning job model
â”‚   â”‚   â”œâ”€â”€ model_info.py      # Model information
â”‚   â”‚   â”œâ”€â”€ chat_session.py    # Chat session
â”‚   â”‚   â””â”€â”€ chat_message.py    # Chat messages
â”‚   â”œâ”€â”€ schemas/               # Pydantic schemas
â”‚   â”œâ”€â”€ api/                   # API routes
â”‚   â”‚   â”œâ”€â”€ finetune.py        # Fine-tuning endpoints
â”‚   â”‚   â”œâ”€â”€ chat.py            # Chat endpoints
â”‚   â”‚   â”œâ”€â”€ model.py           # Model management
â”‚   â”‚   â””â”€â”€ upload.py          # File upload
â”‚   â”œâ”€â”€ services/              # Business logic
â”‚   â”œâ”€â”€ utils/                 # Utility functions
â”‚   â””â”€â”€ streamlit_app.py       # Streamlit interface
â”œâ”€â”€ data/                      # Data storage
â”œâ”€â”€ models/                    # Fine-tuned models
â”œâ”€â”€ uploads/                   # Uploaded files
â”œâ”€â”€ static/                    # Static files
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ run.py                     # Application runner
â”œâ”€â”€ init_db.py                 # Database initialization
â”œâ”€â”€ test_app.py                # Application tests
â””â”€â”€ README.md
```

## ğŸ§ª Testing

Cháº¡y test Ä‘á»ƒ kiá»ƒm tra á»©ng dá»¥ng:
```bash
python test_app.py
```

Khá»Ÿi táº¡o database:
```bash
python init_db.py
```

## ğŸ”§ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p:

1. **Import errors**: Äáº£m báº£o Ä‘Ã£ cÃ i Ä‘áº·t Ä‘áº§y Ä‘á»§ dependencies
2. **Database errors**: Cháº¡y `python init_db.py` Ä‘á»ƒ khá»Ÿi táº¡o database
3. **Configuration errors**: Kiá»ƒm tra file `.env` cÃ³ Ä‘Ãºng Ä‘á»‹nh dáº¡ng
4. **Port conflicts**: Thay Ä‘á»•i port trong file `.env` náº¿u cáº§n

### Logs:
- API logs: Terminal nÆ¡i cháº¡y uvicorn
- Streamlit logs: Terminal nÆ¡i cháº¡y streamlit

## ğŸ“ License

MIT License

## ğŸ¤ Contributing

1. Fork repository
2. Táº¡o feature branch
3. Commit changes
4. Push to branch
5. Táº¡o Pull Request

## ğŸ“ Support

Náº¿u gáº·p váº¥n Ä‘á», hÃ£y:
1. Kiá»ƒm tra logs
2. Cháº¡y `python test_app.py`
3. Táº¡o issue vá»›i thÃ´ng tin lá»—i chi tiáº¿t 

## ğŸ§¹ XoÃ¡ Job History (Lá»‹ch sá»­ Fine-tune)

### CÃ¡ch 1: XoÃ¡ trá»±c tiáº¿p trong database (SQLite)

Náº¿u báº¡n dÃ¹ng SQLite (file `finetuning.db`), cÃ³ thá»ƒ xoÃ¡ job history báº±ng lá»‡nh:

```bash
sqlite3 finetuning.db
```
Sau Ä‘Ã³ trong prompt SQLite:
```sql
DELETE FROM finetune_jobs;
-- hoáº·c xoÃ¡ tá»«ng job theo job_id:
DELETE FROM finetune_jobs WHERE job_id = 'your_job_id';
.exit
```

Hoáº·c dÃ¹ng pháº§n má»m DB Browser for SQLite Ä‘á»ƒ thao tÃ¡c trá»±c quan.

### CÃ¡ch 2: ThÃªm API xoÃ¡ job (tuá»³ chá»n)

Báº¡n cÃ³ thá»ƒ thÃªm endpoint vÃ o `app/api/finetune.py`:
```python
@router.delete("/delete/{job_id}")
async def delete_finetune_job(job_id: str, db: Session = Depends(get_db)):
    job = db.query(FineTuneJob).filter(FineTuneJob.job_id == job_id).first()
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")
    db.delete(job)
    db.commit()
    return {"message": "Job deleted successfully"}
```
Hoáº·c xoÃ¡ toÃ n bá»™:
```python
@router.delete("/delete_all")
async def delete_all_finetune_jobs(db: Session = Depends(get_db)):
    db.query(FineTuneJob).delete()
    db.commit()
    return {"message": "All jobs deleted successfully"}
```
Sau Ä‘Ã³ gá»i API nÃ y báº±ng curl hoáº·c Postman.

### CÃ¡ch 3: XoÃ¡ toÃ n bá»™ database

Chá»‰ cáº§n xoÃ¡ file `finetuning.db` rá»“i khá»Ÿi Ä‘á»™ng láº¡i backend (sáº½ máº¥t toÃ n bá»™ dá»¯ liá»‡u jobs, models, ...). 